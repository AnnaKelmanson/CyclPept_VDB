{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "from rdkit.DataStructs.cDataStructs import ConvertToNumpyArray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rdkit.Chem.Scaffolds.MurckoScaffold import MurckoScaffoldSmiles, MurckoScaffoldSmilesFromSmiles\n",
    "from rdkit.DataStructs.cDataStructs import ExplicitBitVect, TanimotoSimilarity\n",
    "import chromadb\n",
    "from chromadb import Client, Settings, EmbeddingFunction\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage \n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius=4\n",
    "nBits=1024\n",
    "llm_model = 'gpt-3.5-turbo'\n",
    "context_window = 20\n",
    "template = \"{context}. As a language model you have an ability to understand this data based on the data provided, we do not need to build a regression model for a Language model Estimate. You can find relationships and make estimates. Make an estimate for Permeabilty based on SMILES and list of amino acids and on previous data for this row of data {query}. Report the predicted permeability value in the following format: PERMEABILITY(%value).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_morgan_fingerprint(smiles, radius=4, nBits=1024):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits)\n",
    "    arr = np.zeros((1,), dtype=np.int8)\n",
    "    ConvertToNumpyArray(morgan_fp, arr)\n",
    "    return arr.tolist()\n",
    "\n",
    "\n",
    "def find_smiles(text):\n",
    "    pattern = r'SMILES{([^}]*)}'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def chemical_embedding(text):\n",
    "    return get_morgan_fingerprint(find_smiles(text), radius, nBits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChemicalEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input):\n",
    "        smiles = self.find_smiles(input)\n",
    "        if smiles:\n",
    "            return self.get_morgan_fingerprint(smiles)\n",
    "        return None\n",
    "    \n",
    "    def embed_query(self, query):\n",
    "        # This method should handle the embedding of queries\n",
    "        smiles = self.find_smiles(query)\n",
    "        if smiles:\n",
    "            return self.get_morgan_fingerprint(smiles)\n",
    "        return None\n",
    "\n",
    "    def find_smiles(self, text):\n",
    "        pattern = r'SMILES{([^}]*)}'\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_morgan_fingerprint(self, smiles, radius=radius, nBits=nBits):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits)\n",
    "        arr = np.zeros((1,), dtype=np.int8)\n",
    "        ConvertToNumpyArray(morgan_fp, arr)\n",
    "        return arr.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_aldehydes_to_acids(smiles_list):\n",
    "    rxn_smarts = '[CX3H1:1](=O)[H].[OH2:2]>>[CX3:1](=O)[O:2]'\n",
    "    rxn = AllChem.ReactionFromSmarts(rxn_smarts)\n",
    "    \n",
    "    acid_smiles_list = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        mol = Chem.AddHs(mol)\n",
    "        ps = rxn.RunReactants((mol, Chem.MolFromSmiles('O')))\n",
    "        if ps:\n",
    "            product_mol = ps[0][0]  \n",
    "            Chem.SanitizeMol(product_mol)  \n",
    "            acid_smiles = Chem.MolToSmiles(Chem.RemoveHs(product_mol), isomericSmiles=True, canonical=True)\n",
    "            acid_smiles_list.append(acid_smiles)\n",
    "        else:\n",
    "            print('Issue with converting C=O into -COOH')\n",
    "            acid_smiles_list.append(smiles)\n",
    "    \n",
    "    return acid_smiles_list\n",
    "\n",
    "def tokenize_peptides(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    pat = Chem.MolFromSmarts('NC=O')\n",
    "    \n",
    "    # Finding the largest ring\n",
    "    def find_largest_ring(mol):\n",
    "        sssr = Chem.GetSymmSSSR(mol)\n",
    "        largest_ring = max(sssr, key=len)\n",
    "        return set(largest_ring)\n",
    "\n",
    "    largest_ring = find_largest_ring(mol)\n",
    "    matches = mol.GetSubstructMatches(pat)\n",
    "    \n",
    "    emol = Chem.EditableMol(mol)\n",
    "\n",
    "    bonds_to_break = []\n",
    "\n",
    "    for match in matches:\n",
    "        N_idx, C_idx, O_idx = match\n",
    "        if N_idx in largest_ring and C_idx in largest_ring:\n",
    "            bonds_to_break.append((N_idx, C_idx))\n",
    "\n",
    "    # Break bonds \n",
    "    for N_idx, C_idx in sorted(bonds_to_break, reverse=True):  # Sort and reverse to avoid indexing issues\n",
    "        emol.RemoveBond(N_idx, C_idx)\n",
    "\n",
    "    fragmented_mol = emol.GetMol()\n",
    "    frags = Chem.GetMolFrags(fragmented_mol, asMols=True, sanitizeFrags=True)\n",
    "    fragment_smiles = [Chem.MolToSmiles(frag) for frag in frags]\n",
    "\n",
    "    return convert_aldehydes_to_acids(fragment_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../data/train_set.csv')\n",
    "test_set = pd.read_csv('../data/test_set.csv')\n",
    "val_set = pd.read_csv('../data/val_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical VDB generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChemicalEmbeddingGenerator:\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_embedding(chunk):\n",
    "        def extract_smiles(text):\n",
    "            pattern = r'SMILES{([^}]*)}'\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "            return None\n",
    "        smiles_string = extract_smiles(chunk)\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles_string)\n",
    "            if mol is not None:\n",
    "                morgan_fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=4, nBits=1024)\n",
    "                arr = np.zeros((1,), dtype=np.int8)\n",
    "                ConvertToNumpyArray(morgan_fp, arr)\n",
    "                #print(\"Embedding generated successfully.\")\n",
    "                return arr.tolist()\n",
    "            else:\n",
    "                print(\"Invalid SMILES string.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while generating embedding: {e}\")\n",
    "            return None\n",
    "        \n",
    "\n",
    "\n",
    "class DataFrameManager:\n",
    "    def __init__(self):\n",
    "        self.embedding_generator = ChemicalEmbeddingGenerator()\n",
    "        self.chroma_client = chromadb.chromadb.Client()\n",
    "        self.collection_name = \"chemical_data_collection\"\n",
    "        self.collection = self.chroma_client.get_or_create_collection(name=self.collection_name,\n",
    "                                                                      metadata={\"hnsw:space\": \"cosine\"})\n",
    "        \n",
    "    def add_texts_to_collection(self, dataframe, text_column, columns_to_keep):\n",
    "        embeddings_list = []\n",
    "        documents_list = []\n",
    "        metadatas_list = []\n",
    "        ids_list = []\n",
    "        \n",
    "        for index, row in dataframe.iterrows():\n",
    "            embedding = self.embedding_generator.generate_embedding(row[text_column])\n",
    "            if embedding is not None:\n",
    "                unique_id = f\"row_{index}\"\n",
    "                embeddings_list.append(embedding)\n",
    "                documents_list.append(row[text_column])\n",
    "\n",
    "                metadata = {column: row[column] for column in columns_to_keep if row[column] is not None}\n",
    "                \n",
    "                metadatas_list.append(metadata)\n",
    "                ids_list.append(unique_id)\n",
    "        \n",
    "        self.collection.add(\n",
    "            embeddings=embeddings_list,\n",
    "            documents=documents_list,\n",
    "            metadatas=metadatas_list,\n",
    "            ids=ids_list\n",
    "        )\n",
    "        print(\"Data added to collection successfully.\")\n",
    "        return self.collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(query_dict_output):\n",
    "    context=''\n",
    "    for instance in query_dict_output['documents'][0]:\n",
    "        context+=instance + '. '\n",
    "    return context\n",
    "\n",
    "def get_distances(query_dict_output):\n",
    "    return query_dict_output['distances'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_value(input_string):\n",
    "    match = re.search(r'PERMEABILITY\\(([^)]+)\\)', input_string)\n",
    "\n",
    "    if match:\n",
    "        # Extracting the value\n",
    "        permeability_value = match.group(1)\n",
    "    else:\n",
    "        permeability_value = None\n",
    "\n",
    "    return float(permeability_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data added to collection successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Collection(name=chemical_data_collection)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    if manager.collection:\n",
    "        manager.chroma_client.delete_collection(\"chemical_data_collection\")\n",
    "except:\n",
    "    pass\n",
    "manager = DataFrameManager()\n",
    "manager.add_texts_to_collection(train_set, 'Formatted_String', ['Formatted_String'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_from_context(input_string):\n",
    "\n",
    "    match = re.search(r'permeability value is ([\\-\\d\\.]+)', input_string)\n",
    "    permeability_value = match.group(1)\n",
    "\n",
    "    return float(permeability_value)\n",
    "\n",
    "def context_values(context_dict):\n",
    "    permeability = []\n",
    "    for sample in context_dict['documents'][0]:\n",
    "        permeability.append(get_values_from_context(sample))\n",
    "    return permeability\n",
    "\n",
    "def context_stats(context_permeability_list):\n",
    "    ''' The first value is mean, the second one is the closest by Tanimoto structure'''\n",
    "    return statistics.fmean(context_permeability_list), context_permeability_list[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(target, numbers):\n",
    "    return min(numbers, key=lambda x: abs(x - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5.84, -5.8, -5.77]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = test_set['Formatted_String'][0]\n",
    "ground_truth = test_set['PAMPA'][0]\n",
    "sample_from_chroma = manager.collection.query(query_embeddings=[chemical_embedding(text)],\n",
    "    n_results=context_window)\n",
    "\n",
    "context_metrics = context_stats(context_values(sample_from_chroma))\n",
    "\n",
    "prompt = template.format(context=get_context(sample_from_chroma), query=text)\n",
    "openai_llm = ChatOpenAI(model_name=llm_model)\n",
    "predicted_values = []\n",
    "for i in range(3):\n",
    "    response = openai_llm([HumanMessage(content=prompt)])\n",
    "    token_stats = response.response_metadata['token_usage']\n",
    "    predicted_value = extract_value(response.content)\n",
    "    predicted_values.append(predicted_value)\n",
    "mean_llm_response = statistics.fmean(predicted_values)\n",
    "closest_guess = find_closest(ground_truth, predicted_values)\n",
    "predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.85"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.84"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.8525, -5.81)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
